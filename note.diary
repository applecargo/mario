Dec 23, 2018

5:38AM

현재 생각하고 있는, 영상 인식 알고리즘은 다음과 같다. 1) labeling for pixels w/ ROI 2) point testing for contours // 일단 2번 방법으로 해보려고 한다. 그냥 그게 쉬울 거 같아서. // 첫째로는.. 그림을 그린다. // 먼저 네귀퉁이에 AR 마커를 그리고 ROI를 인식하도록 한다. 이것이 인식되면 그 안을 검색한다. // 그리고 스티커 디자인을 2개 해서. osc랑 dac를 만든다. // box가 있고. 안에 마커가 있고. 둘을 연결한다. paint tool: krita를 쓴다. // 그렇게 이상적인 연결된 2개의 신쓰가 표시된 이미지를 한장 출력한다. // 이것이 테스트 대상이다. // ROI 귀퉁이로 그림을 인식하고, 그 안에서 AR 마커를 찾는다. 어쩌면, 귀퉁이 마커가 필요없을 수도 있지만.. 그냥 일단 넣고 시작? .. 아님 그냥 없이? 그래 그냥 없이.. // 신쓰를 찾고 그것의 크기를 표시한다. 그리고, 그 담에 연결 노드들의 위치도 마크한다. // 선을 findContour로 찾고 그것도 표시한다. 여기까지가 되는 시스템을 만든다. // 그담에 신쓰 contour랑 연결선 contour가 intersect 하는지 point tester로 검사한다. // 연결선이 2개의 신쓰를 연결한다는 사실을 인식하면 그것을 연결된 node들의 moment 사이의 직선 연결로 표시한다. // 여기까지 되면, 일단 오케이고. 여러개가 그려진 그림을 다시 만들고, 그것들의 연결을 파악하게 해본다. // 이게 되면, 이 연결에 따라서 automatonism의 오브젝트를 생산하고 연결시키는 pd 패치를 작업한다. // 이것이 되면, 인식의 순간을 말하는 버튼을 단다. arduino를 사용한다. // 이게 되면, rpi로 이동한다. 카메라가 바뀐다. 이때 성능을 파악한다. // 다시 pc에서 bluetooth 연결로 건반/컨트롤러 등을 연결 받는다. // 이것들이 연결된 컨트롤러에 어떻게 반영될지를 정한다. 그리고 만든다.
